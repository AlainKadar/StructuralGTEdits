{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enclosed-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alaink/.local/lib/python3.9/site-packages/sknw-0.13-py3.9.egg/sknw/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sknw\n",
    "print(sknw.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "peripheral-zealand",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disk_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a75dc71550db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnew_canvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnew_canvas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdisk_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisk_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcircle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_canvas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'disk_pos' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('TestData/AgNWN_10um/Binarized/slice0.tiff', cv.IMREAD_GRAYSCALE)\n",
    "#plt.imshow(img)\n",
    "canvas = np.ones(img.shape)\n",
    "new_canvas = canvas\n",
    "new_canvas[disk_pos[0], disk_pos[1]] = 0\n",
    "circle = np.ma.MaskedArray(img, mask=new_canvas)\n",
    "plt.imshow(circle)\n",
    "\n",
    "f.img_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "celtic-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draft\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import os\n",
    "import cv2 as cv\n",
    "import base\n",
    "import process_image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import error\n",
    "import time\n",
    "import functools\n",
    "import gsd.hoomd\n",
    "from skimage.morphology import skeletonize_3d, disk\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "class Network():\n",
    "    \"\"\"Generic SGT graph class: a specialised case of the igraph Graph object with \n",
    "    additional attributes defining geometric features, associated images,\n",
    "    dimensionality etc.\n",
    "    \n",
    "    Initialised from directory containing raw image data\n",
    "    self._2d determined from the number of images with identical dimensions (suggesting a stack when > 1)\n",
    "    \n",
    "    Image shrinking/cropping is carried out at the gsd stage in analysis.\n",
    "    I.e. full images are binarized but cropping their graphs may come after\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, child_dir='/Binarized'):\n",
    "        if not isinstance(directory, str):\n",
    "            raise TypeError\n",
    "            \n",
    "        self.dir = directory\n",
    "        self.child_dir = child_dir\n",
    "        self.stack_dir = self.dir + self.child_dir\n",
    "        \n",
    "        shape = []\n",
    "        for name in sorted(os.listdir(self.dir)):\n",
    "            if not base.Q_img(name):\n",
    "                continue\n",
    "            shape.append(cv.imread(self.dir+'/'+name,cv.IMREAD_GRAYSCALE).shape)\n",
    "        \n",
    "        if len(set(shape)) == len(shape):\n",
    "            self._2d = True\n",
    "            self.dim = 2\n",
    "        else:\n",
    "            self._2d = False\n",
    "            self.dim = 3\n",
    "        \n",
    "    def binarize(self, options_dict=None):\n",
    "        \"\"\"Binarizes stack of experimental images using a set of image processing parameters in options_dict.\n",
    "        Note this enforces that all images have the same shape as the first image encountered by the for loop.\n",
    "        (i.e. the first alphanumeric titled image file)\n",
    "        \"\"\"\n",
    "        \n",
    "        if options_dict is None:\n",
    "            options = self.dir + '/img_options.json'\n",
    "            with open(options) as f:\n",
    "                options_dict = json.load(f)\n",
    "\n",
    "        if not os.path.isdir(self.dir + self.child_dir):\n",
    "            os.mkdir(self.dir + self.child_dir)\n",
    "\n",
    "        i=0\n",
    "        for name in sorted(os.listdir(self.dir)):\n",
    "            if not base.Q_img(name):\n",
    "                continue\n",
    "            else:\n",
    "                img_exp = cv.imread(self.dir+'/'+name,cv.IMREAD_GRAYSCALE)\n",
    "                if i == 0: shape = img_exp.shape\n",
    "                elif img_exp.shape != shape: continue\n",
    "                _, img_bin, _ = process_image.binarize(img_exp, options_dict)\n",
    "                #_, img_bin, _ = process_image.binarize(img_bin, options_dict)\n",
    "                #_, img_bin, _ = process_image.binarize(img_bin, options_dict)\n",
    "                #_, img_bin, _ = process_image.binarize(img_bin, options_dict)\n",
    "                #plt.imshow(img_bin, cmap=cm.gray)\n",
    "                plt.imsave(self.dir+self.child_dir+'/slice'+str(i)+'.tiff', img_bin, cmap=cm.gray)\n",
    "                i+=1\n",
    "        \n",
    "    def stack_to_gsd(self, name='skel.gsd', crop=None, skeleton=True, rotate=None, debubble=None):\n",
    "        \"\"\"Writes a .gsd file from the object's directory.\n",
    "        The name of the written .gsd is set as an attribute so it may be easily matched with its Graph object \n",
    "        Running this also sets the positions, shape attributes\n",
    "        \n",
    "        For 2D graphs, the first element of the 3D position list is all 0s. So the gsd y corresponds to the graph\n",
    "        x and the gsd z corresponds to the graph y.\n",
    "\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        self.gsd_name = self.stack_dir + '/' + name\n",
    "        self.gsd_dir = os.path.split(self.gsd_name)[0]\n",
    "        img_bin=[]\n",
    "\n",
    "        #Initilise i such that it starts at the lowest number belonging to the images in the stack_dir\n",
    "        #First require boolean mask to filter out non image files\n",
    "        olist = np.asarray(sorted(os.listdir(self.stack_dir)))\n",
    "        mask = list(base.Q_img(olist[i]) for i in range(len(olist)))\n",
    "        if len(mask) == 0:\n",
    "            raise error.ImageDirectoryError(self.stack_dir)\n",
    "        fname = sorted(olist[mask])[0] #First name\n",
    "        i = int(os.path.splitext(fname)[0][5:]) #Strip file type and 'slice' then convert to int\n",
    "\n",
    "        #Generate 3d (or 2d) array from stack\n",
    "        for fname in sorted(os.listdir(self.stack_dir)):\n",
    "            if base.Q_img(fname):\n",
    "                img_slice = cv.imread(self.stack_dir+'/slice'+str(i)+'.tiff',cv.IMREAD_GRAYSCALE)\n",
    "                if rotate is not None:\n",
    "                    image_center = tuple(np.array(img_slice.shape[1::-1]) / 2)\n",
    "                    rot_mat = cv.getRotationMatrix2D(image_center, rotate, 1.0)\n",
    "                    img_slice = cv.warpAffine(img_slice, rot_mat, img_slice.shape[1::-1], flags=cv.INTER_LINEAR)\n",
    "                img_bin.append(img_slice)\n",
    "                i=i+1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        #For 2D images, img_bin_3d.shape[0] == 1\n",
    "        img_bin = np.asarray(img_bin)\n",
    "        self.img_bin_3d = img_bin\n",
    "        self.img_bin = img_bin\n",
    "\n",
    "        #Note that numpy array slicing operations are carried out in reverse order!\n",
    "        #(...hence crop 2 and 3 before 0 and 1)\n",
    "        if crop and self._2d:\n",
    "            self.img_bin = self.img_bin[:, crop[2]:crop[3], crop[0]:crop[1]]\n",
    "            #img_bin = img_bin[crop[0]:crop[1], crop[2]:crop[3]]\n",
    "        elif crop:\n",
    "            #TODO figure tf this bit out\n",
    "            self.img_bin = self.img_bin[crop[0]:crop[1], crop[2]:crop[3], crop[4]:crop[5]]\n",
    "\n",
    "        assert self.img_bin_3d.shape[1] > 1\n",
    "        assert self.img_bin_3d.shape[2] > 1\n",
    "        \n",
    "        self.img_bin_3d = self.img_bin            #Always 3d, even for 2d images\n",
    "        self.img_bin = np.squeeze(self.img_bin)   #3d for 3d images, 2d otherwise\n",
    "\n",
    "        assert self.img_bin_3d.shape[1] == self.img_bin.shape[0]\n",
    "        assert self.img_bin_3d.shape[2] == self.img_bin.shape[1]\n",
    "        \n",
    "        if skeleton:\n",
    "            self.skeleton = skeletonize_3d(np.asarray(self.img_bin))\n",
    "            self.skeleton_3d = skeletonize_3d(np.asarray(self.img_bin_3d))\n",
    "            #self.skeleton_3d = np.swapaxes(self.skeleton_3d, 1, 2)\n",
    "        else:\n",
    "            self.img_bin = np.asarray(self.img_bin)\n",
    "\n",
    "        positions = np.asarray(np.where(np.asarray(self.skeleton_3d) == 255)).T\n",
    "        self.shape = np.asarray(list(max(positions.T[i])+1 for i in (0,1,2)[0:self.dim]))\n",
    "        self.positions = positions\n",
    "\n",
    "        print(positions)\n",
    "        print(self.img_bin.shape)\n",
    "\n",
    "        with gsd.hoomd.open(name=self.gsd_name, mode='wb') as f:\n",
    "            s = gsd.hoomd.Snapshot()\n",
    "            s.particles.N = len(positions)\n",
    "            s.particles.position = base.shift(positions)\n",
    "            s.particles.types = ['A']\n",
    "            s.particles.typeid = ['0']*s.particles.N\n",
    "            f.append(s)\n",
    "\n",
    "        end = time.time()\n",
    "        print('Ran stack_to_gsd() in ', end-start, 'for gsd with ', len(positions), 'particles')\n",
    "\n",
    "        if debubble is not None: self = base.debubble(self, debubble)\n",
    "\n",
    "        assert self.img_bin.shape == self.skeleton.shape\n",
    "        assert self.img_bin_3d.shape == self.skeleton_3d.shape\n",
    "\n",
    "        \n",
    "    def stack_to_circular_gsd(self, radius, name='circle.gsd', rotate=None, debubble=None, skeleton=True):\n",
    "        \"\"\"Writes a cicular .gsd file from the object's directory.\n",
    "        Currently only capable of 2D graphs\n",
    "        Unlike stack_to_gsd, the axis of rotation is not the centre of the image, but the point (radius,radius)\n",
    "        The name of the written .gsd is set as an attribute so it may be easily matched with its Graph object \n",
    "        Running this also sets the positions, shape attributes\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        self.gsd_name = self.stack_dir + '/' + name\n",
    "        self.gsd_dir = os.path.split(self.gsd_name)[0]\n",
    "        img_bin=[]\n",
    "        \n",
    "        #Initilise i such that it starts at the lowest number belonging to the images in the stack_dir\n",
    "        #First require boolean mask to filter out non image files\n",
    "        olist = np.asarray(sorted(os.listdir(self.stack_dir)))\n",
    "        mask = list(base.Q_img(olist[i]) for i in range(len(olist)))\n",
    "        if len(mask) == 0:\n",
    "            raise error.ImageDirectoryError(self.stack_dir)\n",
    "        fname = sorted(olist[mask])[0] #First name\n",
    "        i = int(os.path.splitext(fname)[0][5:]) #Strip file type and 'slice' then convert to int\n",
    "        \n",
    "        img_slice = cv.imread(self.stack_dir+'/slice'+str(i)+'.tiff',cv.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        #Read the image\n",
    "        for fname in sorted(os.listdir(self.stack_dir)):\n",
    "            if base.Q_img(fname):\n",
    "                img_slice = cv.imread(self.stack_dir+'/slice'+str(i)+'.tiff',cv.IMREAD_GRAYSCALE)\n",
    "                if rotate is not None:\n",
    "                    axis_of_rot = tuple((radius,radius))\n",
    "                    #image_center = tuple(np.array(img_slice.shape[1::-1]) / 2)\n",
    "                    rot_mat = cv.getRotationMatrix2D(axis_of_rot, rotate, 1.0)\n",
    "                    img_slice = cv.warpAffine(img_slice, rot_mat, img_slice.shape[1::-1], flags=cv.INTER_LINEAR)\n",
    "                img_bin.append(img_slice)\n",
    "                i=i+1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        #For 2D images, img_bin_3d.shape[0] == 1\n",
    "        img_bin = np.asarray(img_bin)\n",
    "        \n",
    "        self.img_bin_3d = img_bin            #Always 3d, even for 2d images\n",
    "        self.img_bin = np.squeeze(img_bin)   #3d for 3d images, 2d otherwise\n",
    "        \n",
    "        #Note that numpy array slicing operations are carried out in reverse order!\n",
    "        #(...hence crop 2 and 3 before 0 and 1)\n",
    "        assert self._2d\n",
    "\n",
    "\n",
    "        canvas = np.ones(self.img_bin.shape)\n",
    "        disk_pos = np.asarray(np.where(disk(radius)!=0)).T\n",
    "        canvas[disk_pos[0], disk_pos[1]] = 0\n",
    "        self.img_bin = np.ma.MaskedArray(self.img_bin, mask=canvas)\n",
    "        self.img_bin = np.ma.filled(self.img_bin, fill_value=0)\n",
    "        \n",
    "        canvas = np.ones(self.img_bin_3d.shape)\n",
    "        disk_pos = np.asarray(np.where(disk(radius)!=0)).T\n",
    "        disk_pos = np.array([np.zeros(len(disk_pos)), disk_pos.T[0], disk_pos.T[1]], dtype=int)\n",
    "        canvas[disk_pos[0], disk_pos[1], disk_pos[2]] = 0\n",
    "        self.img_bin_3d = np.ma.MaskedArray(self.img_bin_3d, mask=canvas)\n",
    "        self.img_bin_3d = np.ma.filled(self.img_bin_3d, fill_value=0)\n",
    "        self.img_bin = self.img_bin_3d[0]\n",
    "        \n",
    "        assert self.img_bin_3d.shape[1] > 1\n",
    "        assert self.img_bin_3d.shape[2] > 1\n",
    "        \n",
    "        if skeleton:\n",
    "            self.skeleton = skeletonize_3d(np.asarray(self.img_bin))\n",
    "            self.skeleton_3d = skeletonize_3d(np.asarray(self.img_bin_3d))\n",
    "        else:\n",
    "            self.img_bin = np.asarray(self.img_bin)\n",
    "        \n",
    "        positions = np.asarray(np.where(np.asarray(self.skeleton_3d) == 255)).T\n",
    "        self.shape = np.asarray(list(max(positions.T[i])+1 for i in (0,1,2)[0:self.dim]))\n",
    "        self.positions = positions\n",
    "        \n",
    "        with gsd.hoomd.open(name=self.gsd_name, mode='wb') as f:\n",
    "            s = gsd.hoomd.Snapshot()\n",
    "            s.particles.N = len(positions)\n",
    "            s.particles.position = base.shift(positions)\n",
    "            s.particles.types = ['A']\n",
    "            s.particles.typeid = ['0']*s.particles.N\n",
    "            f.append(s)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Ran stack_to_gsd() in ', end-start, 'for gsd with ', len(positions), 'particles')\n",
    "        \n",
    "        if debubble is not None: self = base.debubble(self, debubble)\n",
    "            \n",
    "        assert self.img_bin.shape == self.skeleton.shape\n",
    "        assert self.img_bin_3d.shape == self.skeleton_3d.shape    \n",
    "        \n",
    "        \n",
    "    def G_u(self):\n",
    "        \"\"\"Sets unweighted igraph object as an attribute\n",
    "        \"\"\"\n",
    "        G =  base.gsd_to_G(self.gsd_name, _2d = self._2d)\n",
    "        self.Gr = G\n",
    "        self.shape = list(max(list(self.Gr.vs[i]['o'][j] for i in range(self.Gr.vcount()))) for j in (0,1,2)[0:self.dim])\n",
    "        \n",
    "    def weighted_Laplacian(self):\n",
    "\n",
    "        L=np.asarray(self.Gr.laplacian(weights='weight'))\n",
    "        self.L = L\n",
    "\n",
    "class ResistiveNetwork(Network):\n",
    "    \"\"\"Child of generic SGT Network class.\n",
    "    Equipped with methods for analysing resistive flow networks\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        super().__init__(directory)\n",
    "        \n",
    "    def potential_distribution(self, plane, boundary1, boundary2, R_j=0, rho_dim=1, F_dim=1):\n",
    "        \"\"\"Solves for the potential distribution in a weighted network.\n",
    "        Source and sink nodes are connected according to a penetration boundary condition.\n",
    "        Sets the corresponding weighted Laplacian, potential and flow attributes.\n",
    "        The 'plane' arguement defines the axis along which the boundary arguements refer to.\n",
    "        R_j='infinity' enables the unusual case of all edges having the same unit resistance.\n",
    "        \n",
    "        NOTE: Critical that self.G_u() is called before every self.potential_distribution()\n",
    "        TODO: Remove this requirement or add an error to warn\n",
    "        \"\"\"\n",
    "        self.Gr = base.sub_G(self.Gr)\n",
    "        print('post sub has ', self.Gr.vcount(), ' nodes')\n",
    "        if R_j != 'infinity':\n",
    "            print(self.Gr.vcount())\n",
    "            self.Gr_connected = base.add_weights(self, weight_type='Resistance', R_j=R_j, rho_dim=rho_dim)\n",
    "            print(self.Gr.vcount())\n",
    "            weight_array = np.asarray(self.Gr_connected.es['weight']).astype(float)\n",
    "            weight_array = weight_array[~np.isnan(weight_array)]\n",
    "            self.edge_weights = weight_array\n",
    "            weight_avg =np.mean(weight_array)\n",
    "        else:\n",
    "            self.Gr_connected.es['weight'] = np.ones(self.Gr_connected.ecount())\n",
    "            weight_avg = 1\n",
    "\n",
    "        #Add source and sink nodes:\n",
    "        source_id = max(self.Gr_connected.vs).index + 1\n",
    "        sink_id = source_id + 1\n",
    "        self.Gr_connected.add_vertices(2)\n",
    "\n",
    "        print('Graph has max ', self.shape)\n",
    "        axes = np.array([0,1,2])[0:self.dim]\n",
    "        indices = axes[axes!=plane]\n",
    "        plane_centre1 = np.zeros(self.dim, dtype=int)\n",
    "        delta = np.zeros(self.dim, dtype=int)\n",
    "        delta[plane] = 10 #Arbitrary. Standardize?\n",
    "        for i in indices: plane_centre1[i] = self.shape[i]/2\n",
    "        plane_centre2 = np.copy(plane_centre1)\n",
    "        plane_centre2[plane] = self.shape[plane]\n",
    "        source_coord = plane_centre1 - delta \n",
    "        sink_coord = plane_centre2 + delta\n",
    "        print('source coord is ', source_coord)\n",
    "        print('sink coord is ', sink_coord)\n",
    "        self.Gr_connected.vs[source_id]['o'] = source_coord\n",
    "        self.Gr_connected.vs[sink_id]['o'] = sink_coord\n",
    "\n",
    "    #Connect nodes on a given boundary to the external current nodes\n",
    "        print('Before connecting external nodes, G has vcount ', self.Gr_connected.vcount())\n",
    "        for node in self.Gr_connected.vs:\n",
    "            if node['o'][plane] > boundary1[0] and node['o'][plane] < boundary1[1]:\n",
    "                self.Gr_connected.add_edges([(node.index, source_id)])\n",
    "                self.Gr_connected.es[self.Gr_connected.get_eid(node.index,source_id)]['weight'] = weight_avg\n",
    "                self.Gr_connected.es[self.Gr_connected.get_eid(node.index,source_id)]['pts'] = base.connector(source_coord,node['o'])\n",
    "            if node['o'][plane] > boundary2[0] and node['o'][plane] < boundary2[1]:\n",
    "                self.Gr_connected.add_edges([(node.index, sink_id)])\n",
    "                self.Gr_connected.es[self.Gr_connected.get_eid(node.index,sink_id)]['weight'] = weight_avg \n",
    "                self.Gr_connected.es[self.Gr_connected.get_eid(node.index,sink_id)]['pts'] = base.connector(sink_coord,node['o'])\n",
    "\n",
    "    #Write skeleton connected to external node\n",
    "        print(self.Gr_connected.is_connected(), ' connected')\n",
    "        print('After connecting external nodes, G has vcount ', self.Gr_connected.vcount())\n",
    "        connected_name = os.path.split(self.gsd_name)[0] + '/connected_' + os.path.split(self.gsd_name)[1] \n",
    "        #connected_name = self.stack_dir + '/connected_' + self.gsd_name \n",
    "        base.G_to_gsd(self.Gr_connected, connected_name)\n",
    "\n",
    "        self.weighted_Laplacian()\n",
    "        F = np.zeros(sink_id+1)\n",
    "        print(F.shape,'F')\n",
    "        print(self.L.shape, 'L')\n",
    "        F[source_id] = F_dim\n",
    "        F[sink_id] = -F_dim\n",
    "        np.save(self.stack_dir+'/L.npy',self.L)\n",
    "        np.save(self.stack_dir+'/F.npy',F)\n",
    "        P = np.matmul(np.linalg.pinv(self.L, hermitian=True),F)\n",
    "        np.save(self.stack_dir+'/P.npy',P)\n",
    "\n",
    "        self.P = P\n",
    "        self.F = F\n",
    "\n",
    "class StructuralNetwork(Network):\n",
    "    \"\"\"Child of generic SGT Network class.\n",
    "    Equipped with methods for analysing structural networks\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        super().__init__(directory)\n",
    "        \n",
    "    def G_calc(self):\n",
    "        avg_indices = dict()\n",
    "\n",
    "        operations = [self.Gr.diameter, self.Gr.density, self.Gr.transitivity_undirected, self.Gr.assortativity_degree]\n",
    "        names = ['Diameter', 'Density', 'Clustering', 'Assortativity by degree']\n",
    "\n",
    "        for operation,name in zip(operations,names):\n",
    "            start = time.time()\n",
    "            avg_indices[name] = operation()\n",
    "            end = time.time()\n",
    "            print('Calculated ', name, ' in ', end-start)\n",
    "            \n",
    "        self.G_attributes = avg_indices\n",
    "        \n",
    "    def node_calc(self):\n",
    "        self.Betweenness = self.Gr.betweenness()\n",
    "        self.Closeness = self.Gr.closeness()\n",
    "        self.Degree = self.Gr.degree()\n",
    "\n",
    "def Node_labelling(g, attribute, attribute_name, filename):\n",
    "    \"\"\"\n",
    "    Function saves a new .gsd which has the graph in g.Gr labelled with the node attributes in attribute\n",
    "    \"\"\"\n",
    "    \n",
    "    assert g.Gr.vcount() == len(attribute)\n",
    "    \n",
    "    #save_name = os.path.split(prefix)[0] + '/'+attribute_name + os.path.split(prefix)[1]\n",
    "    save_name = g.dir + '/' + filename\n",
    "    if os.path.exists(save_name):\n",
    "        mode = 'rb+'\n",
    "    else:\n",
    "        mode = 'wb'\n",
    "\n",
    "    f = gsd.hoomd.open(name=save_name, mode=mode)\n",
    "    \n",
    "    #Must segregate position list into a node_position section and edge_position\n",
    "    node_positions = np.asarray(list(g.Gr.vs()[i]['o'] for i in range(g.Gr.vcount())))\n",
    "    positions = node_positions\n",
    "    for edge in g.Gr.es():\n",
    "        positions=np.vstack((positions,edge['pts']))\n",
    "    positions = np.unique(positions, axis=0)\n",
    "    if g._2d:\n",
    "        node_positions = np.hstack((np.zeros((len(node_positions),1)),node_positions))\n",
    "        positions = np.hstack((np.zeros((len(positions),1)),positions))\n",
    "\n",
    "    #node_positions = base.shift(node_positions)\n",
    "    #positions = base.shift(positions)\n",
    "    s = gsd.hoomd.Snapshot()\n",
    "    N = len(positions)\n",
    "    s.particles.N = N\n",
    "    s.particles.position = positions\n",
    "    s.particles.types = ['Edge', 'Node']\n",
    "    s.particles.typeid = [0]*N\n",
    "    L = list(max(positions.T[i])*2 for i in (0,1,2))\n",
    "    #s.configuration.box = [L[0]/2, L[1]/2, L[2]/2, 0, 0, 0]\n",
    "    s.configuration.box = [1,1,1,0,0,0]\n",
    "    s.log['particles/'+attribute_name] = [np.NaN]*N\n",
    "    start = time.time()\n",
    "\n",
    "    j=0\n",
    "    for i,particle in enumerate(positions):\n",
    "        node_id = np.where(np.all(positions[i] == node_positions, axis=1) == True)[0]\n",
    "        if len(node_id) == 0: \n",
    "            continue\n",
    "        else:\n",
    "            s.log['particles/'+attribute_name][i] = attribute[node_id[0]]\n",
    "            s.particles.typeid[i] = 1\n",
    "            j+=1\n",
    "    \n",
    "    f.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "false-question",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0   50]\n",
      " [   0    0   54]\n",
      " [   0    0  144]\n",
      " ...\n",
      " [   0 1756 1907]\n",
      " [   0 1756 1916]\n",
      " [   0 1756 1963]]\n",
      "(1757, 2033)\n",
      "Ran stack_to_gsd() in  4.061809062957764 for gsd with  239234 particles\n",
      "Ran debubble in  3.6325650215148926 for an image with shape  (1, 1757, 2033)\n"
     ]
    }
   ],
   "source": [
    "scale=1\n",
    "img_options={\"Thresh_method\":1, \"gamma\": 2.34, \"md_filter\": 0, \"g_blur\": 1, \"autolvl\": 0,\n",
    "             \"fg_color\":1, \"laplacian\": 0, \"scharr\": 1, \"sobel\":0 , \"lowpass\": 1, \"asize\": int((103*scale))*2+1,\n",
    "             \"bsize\":int((43*scale))*2+1, \"wsize\": int((10*scale))*2+1, \"thresh\": 127}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "img_options={\"Thresh_method\":1, \"gamma\": 2.34, \"md_filter\": 0, \"g_blur\": 1, \"autolvl\": 0,\n",
    "             \"fg_color\":1, \"laplacian\": 0, \"scharr\": 1, \"sobel\":1 , \"lowpass\": 1, \"asize\": 103,\n",
    "             \"bsize\":43, \"wsize\": 10, \"thresh\": 127}\n",
    "\"\"\"\n",
    "f = ResistiveNetwork('TestData/Mxene/1')\n",
    "#f.binarize(options_dict=img_options)\n",
    "f.stack_to_gsd(debubble=[disk(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "medical-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran stack_to_gsd() in  0.4855809211730957 for gsd with  57680 particles\n",
      "Ran debubble in  0.4514319896697998 for an image with shape  (1, 1018, 1536)\n",
      "gsd_to_G canvas has shape  (799, 799)\n",
      "[[  3 361]]\n",
      "(0, 30, array([[  3, 361],\n",
      "       [  4, 360],\n",
      "       [  5, 359],\n",
      "       [  6, 358],\n",
      "       [  7, 358],\n",
      "       [  8, 357],\n",
      "       [  9, 356],\n",
      "       [ 10, 355],\n",
      "       [ 11, 354],\n",
      "       [ 12, 353],\n",
      "       [ 13, 352],\n",
      "       [ 14, 351],\n",
      "       [ 15, 351],\n",
      "       [ 16, 351],\n",
      "       [ 17, 351],\n",
      "       [ 18, 351],\n",
      "       [ 19, 352],\n",
      "       [ 20, 353]], dtype=int16))\n",
      "Ran gsd_to_G in  2.523740768432617 for a graph with  4270 nodes.\n",
      "pre sub has  4270  nodes\n",
      "post sub has  4043  nodes\n",
      "post sub has  4043  nodes\n",
      "4043\n",
      "4043\n",
      "Graph has max  [798, 797]\n",
      "source coord is  [399 -10]\n",
      "sink coord is  [399 807]\n",
      "Before connecting external nodes, G has vcount  4045\n",
      "True  connected\n",
      "After connecting external nodes, G has vcount  4045\n",
      "(4045,) F\n",
      "(4045, 4045) L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "implicit data copy when writing chunk: log/particles/P\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Examples:\n",
    "f = ResistiveNetwork('TestData/AgNWN_10um')\n",
    "f.binarize()\n",
    "f.stack_to_gsd(crop=[300,600,0,500], debubble=[disk(3)])\n",
    "f.G_u()\n",
    "f.potential_distribution(1, [0,20], [480,500])\n",
    "base.Node_labelling(f, f.P, 'P', 'test1.gsd')\n",
    "\n",
    "g = ResistiveNetwork('TestData/pores-hi-res-crop')\n",
    "g.stack_to_gsd(crop=[0,100,0,100,0,100], debubble=[ball(3)])\n",
    "g.G_u()\n",
    "g.potential_distribution(0, [0,20], [80,100])\n",
    "base.Node_labelling(g, g.P, 'P', 'test2.gsd')\n",
    "\n",
    "s = StructuralNetwork('TestData/fibres-hi-res-crop')\n",
    "s.stack_to_gsd(crop=[0,100,0,100,0,100])\n",
    "s.G_u()\n",
    "s.node_calc()\n",
    "base.Node_labelling(s, s.Degree, 'Degree', 'test3.gsd')\n",
    "\"\"\"\n",
    "\n",
    "f = ResistiveNetwork('TestData/AgNWN_10um')\n",
    "f.stack_to_circular_gsd(400, rotate=45, debubble=[disk(1)])\n",
    "f.G_u()\n",
    "f.potential_distribution(1, [0,50], [750,800])\n",
    "Node_labelling(f, f.P, 'P', 'test1.gsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "innovative-marble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   4]\n",
      " [  0   0   5]\n",
      " [  0   0   6]\n",
      " ...\n",
      " [  0 718 673]\n",
      " [  0 718 674]\n",
      " [  0 718 675]]\n",
      "(719, 719)\n",
      "Ran stack_to_gsd() in  0.24706196784973145 for gsd with  59554 particles\n",
      "Ran debubble in  0.27390527725219727 for an image with shape  (1, 719, 719)\n",
      "gsd_to_G canvas has shape  (719, 719)\n",
      "[[ 0 41]]\n",
      "(0, 14, array([[ 0, 41],\n",
      "       [ 0, 42],\n",
      "       [ 0, 43],\n",
      "       [ 0, 44],\n",
      "       [ 0, 45],\n",
      "       [ 0, 46],\n",
      "       [ 0, 47],\n",
      "       [ 0, 48],\n",
      "       [ 0, 49],\n",
      "       [ 0, 50],\n",
      "       [ 1, 51],\n",
      "       [ 1, 52],\n",
      "       [ 1, 53],\n",
      "       [ 1, 54],\n",
      "       [ 1, 55],\n",
      "       [ 1, 56],\n",
      "       [ 1, 57],\n",
      "       [ 1, 58],\n",
      "       [ 1, 59],\n",
      "       [ 1, 60],\n",
      "       [ 1, 61],\n",
      "       [ 1, 62],\n",
      "       [ 1, 63],\n",
      "       [ 1, 64],\n",
      "       [ 1, 65],\n",
      "       [ 1, 66],\n",
      "       [ 1, 67],\n",
      "       [ 1, 68],\n",
      "       [ 1, 69],\n",
      "       [ 1, 70],\n",
      "       [ 1, 71],\n",
      "       [ 1, 72],\n",
      "       [ 1, 73],\n",
      "       [ 2, 74],\n",
      "       [ 2, 75],\n",
      "       [ 3, 76],\n",
      "       [ 4, 77],\n",
      "       [ 4, 78],\n",
      "       [ 4, 79],\n",
      "       [ 3, 80],\n",
      "       [ 2, 81],\n",
      "       [ 2, 82],\n",
      "       [ 2, 83],\n",
      "       [ 2, 84],\n",
      "       [ 2, 85],\n",
      "       [ 2, 86],\n",
      "       [ 2, 87]], dtype=int16))\n",
      "Ran gsd_to_G in  2.4754669666290283 for a graph with  2653 nodes.\n",
      "pre sub has  2653  nodes\n",
      "post sub has  2273  nodes\n",
      "post sub has  2273  nodes\n",
      "2273\n",
      "2273\n",
      "Graph has max  [718, 718]\n",
      "source coord is  [-10 359]\n",
      "sink coord is  [728 359]\n",
      "Before connecting external nodes, G has vcount  2275\n",
      "True  connected\n",
      "After connecting external nodes, G has vcount  2275\n",
      "(2275,) F\n",
      "(2275, 2275) L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "implicit data copy when writing chunk: log/particles/P\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2275\n",
      "2653\n",
      "[[  0   0  14]\n",
      " [  0   0  27]\n",
      " [  0   0 199]\n",
      " ...\n",
      " [  0 718 659]\n",
      " [  0 718 660]\n",
      " [  0 718 671]]\n",
      "(719, 719)\n",
      "Ran stack_to_gsd() in  0.4410579204559326 for gsd with  57962 particles\n",
      "Ran debubble in  0.3710489273071289 for an image with shape  (1, 719, 719)\n",
      "gsd_to_G canvas has shape  (719, 719)\n",
      "[[1 0]]\n",
      "(1, 63, array([[ 1, 68],\n",
      "       [ 1, 67],\n",
      "       [ 1, 66],\n",
      "       [ 1, 65],\n",
      "       [ 1, 64],\n",
      "       [ 1, 63],\n",
      "       [ 1, 62],\n",
      "       [ 2, 61],\n",
      "       [ 2, 60],\n",
      "       [ 3, 59],\n",
      "       [ 3, 58],\n",
      "       [ 3, 57],\n",
      "       [ 3, 56],\n",
      "       [ 4, 55],\n",
      "       [ 4, 54],\n",
      "       [ 4, 53],\n",
      "       [ 5, 52],\n",
      "       [ 6, 51],\n",
      "       [ 7, 50],\n",
      "       [ 7, 49],\n",
      "       [ 8, 48],\n",
      "       [ 9, 47],\n",
      "       [ 9, 46],\n",
      "       [ 9, 45],\n",
      "       [10, 44],\n",
      "       [11, 43],\n",
      "       [12, 42]], dtype=int16))\n",
      "Ran gsd_to_G in  2.656190872192383 for a graph with  3135 nodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alaink/.local/lib/python3.9/site-packages/StructuralGT-1.0.1b2-py3.9.egg/StructuralGT/GetWeights_3d.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre sub has  3135  nodes\n",
      "post sub has  2888  nodes\n",
      "post sub has  2888  nodes\n",
      "2888\n",
      "2888\n",
      "Graph has max  [718, 718]\n",
      "source coord is  [-10 359]\n",
      "sink coord is  [728 359]\n",
      "Before connecting external nodes, G has vcount  2890\n",
      "True  connected\n",
      "After connecting external nodes, G has vcount  2890\n",
      "(2890,) F\n",
      "(2890, 2890) L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "implicit data copy when writing chunk: log/particles/P\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2890\n",
      "3135\n"
     ]
    }
   ],
   "source": [
    "#Rotation test\n",
    "#Continuous rotation analysis\n",
    "#Testing base.py implementation\n",
    "#This implementation rotates the image itself\n",
    "\n",
    "#######################################################\n",
    "## USE THIS CELL FOR TESTING THE ABOVE DECLARATIONS ##\n",
    "## USE A SEPARATE NOTEBOOK FOR TESTING network.py   ##\n",
    "#######################################################\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.morphology import binary_closing, disk, ball, skeletonize_3d\n",
    "import network\n",
    "g = network.ResistiveNetwork('TestData/AgNWN_10um')\n",
    "g.binarize()\n",
    "\n",
    "#thetas = np.linspace(0.001,350, 4)\n",
    "thetas = (0,45)\n",
    "\n",
    "#crop = 359\n",
    "\n",
    "#Need to reassign weights from a temporary rotated binary image\n",
    "#First write the temporary image\n",
    "#Must calculate positions for the crop because this crop is origin cornered (and not origin centred, like the one above)\n",
    "img_bin = cv.imread(g.stack_dir+'/slice0.tiff') #Original image\n",
    "image_center = tuple(np.array(img_bin.shape[1::-1]) / 2)\n",
    "short_length = img_bin.shape[img_bin.shape == max(img_bin.shape)]\n",
    "long_length = max(img_bin.shape)\n",
    "ISS = (short_length**2/2)**0.5\n",
    "L1 = int((long_length - ISS)/2)\n",
    "L3 = int(ISS+L1)\n",
    "L2 = int((short_length - ISS)/2)\n",
    "L4 = int(ISS+L2)\n",
    "o_corn_crop = [L2,L1,L4,L3]\n",
    "dims = L2-L1\n",
    "\n",
    "\n",
    "\n",
    "R_j = 0\n",
    "O_eff_df = []\n",
    "Ax_df = []\n",
    "Ay_df = []\n",
    "theta_df = []\n",
    "nodes = []\n",
    "for theta in thetas:\n",
    "    g.stack_to_gsd(name='Rotations/ObjectImplementation/rot_skel.gsd', crop=[L1,L3,L2,L4], rotate=theta, debubble=[disk(2)])\n",
    "    g.G_u()\n",
    "    measuring_graph = base.add_weights(g, weight_type='Resistance', R_j=R_j)\n",
    "    g.potential_distribution(0, [0,20], [727-20,727], R_j=R_j, rho_dim=0.89, F_dim=1)\n",
    "    base.Node_labelling(g, g.P, 'P', 'take2.gsd')\n",
    "    print(g.Gr_connected.vcount())\n",
    "    print(measuring_graph.vcount())\n",
    "    \n",
    "    #Ax, Ay = base.gyration_moments(g.Gr, sampling = 0.1)\n",
    "    #L = g.L\n",
    "    #Q = np.linalg.pinv(L)\n",
    "    #O_eff = Q[-1,-1]+Q[-2,-2]-2*Q[-1,-2]\n",
    "    \n",
    "    nodes.append(g.Gr.vcount())\n",
    "    df_cont = pd.DataFrame(columns=['Theta','O_eff','Ax','Ay'])\n",
    "    df_cont['O_eff'] = O_eff_df\n",
    "    df_cont['Ax'] = Ax_df\n",
    "    df_cont['Ay'] = Ay_df\n",
    "    df_cont['Theta'] = theta_df\n",
    "    #df_cont.to_csv('AgNWN.csv')\n",
    "\n",
    "    df_cont\n",
    "    #print(theta, O_eff, Ax, Ay)\n",
    "    \n",
    "    #stop\n",
    "    \n",
    "    \n",
    "    #O_eff_df.append(O_eff)\n",
    "    #Ax_df.append(Ax)\n",
    "    #Ay_df.append(Ay)\n",
    "    #theta_df.append(theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.asarray(np.where(np.asarray(g.img_bin_3d)!=0)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "innovative-companion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.        ,  0.6       ,  0.06      , ...,  0.66666667,\n",
       "       10.        ,  0.02366864])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-discovery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.img_bin_3d\n",
    "img_bin = np.swapaxes(g.img_bin_3d, 0, 2)\n",
    "\n",
    "crop = o_corn_crop\n",
    "img_bin[crop[2]:crop[3], crop[0]:crop[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(thetas,nodes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_bin=[]\n",
    "img_bin.append(img_slice)\n",
    "img_bin = np.asarray(img_bin)\n",
    "img_bin = np.swapaxes(img_bin, 0, 2)\n",
    "print(img_bin.shape)\n",
    "img_bin = img_bin[crop[2]:crop[3],crop[0]:crop[1]]\n",
    "print(img_bin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(_class,method):\n",
    "    \"\"\"Print the runtime of the decorated function\"\"\"\n",
    "    @functools.wraps(method)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start_time = time.perf_counter()    # 1\n",
    "        value = _method(*args, **kwargs)\n",
    "        end_time = time.perf_counter()      # 2\n",
    "        run_time = end_time - start_time    # 3\n",
    "        print(f\"Finished {method.__name__!r} in {run_time:.4f} secs\")\n",
    "        print(_class)\n",
    "        print(method)\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
