{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "celtic-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draft\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import os\n",
    "import cv2 as cv\n",
    "import base\n",
    "import process_image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import error\n",
    "import time\n",
    "import functools\n",
    "import gsd.hoomd\n",
    "from skimage.morphology import skeletonize_3d\n",
    "import root\n",
    "\n",
    "class Graph(object):\n",
    "    \"\"\"Generic SGT graph class: a specialised case of igraph Graph object with additional attributes\n",
    "    defining geometric features, associated images, dimensionality etc\n",
    "    \n",
    "    Initialised from directory containing raw image data\n",
    "    self._2d determined from the number of images with identical dimensions (suggesting a stack when > 1)\n",
    "    \n",
    "    Image shrinking/cropping is carried out at the gsd stage in analysis.\n",
    "    I.e. full images are binarized but cropping their graphs may come after\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, child_dir='/Binarized'):\n",
    "        if not isinstance(directory, str):\n",
    "            raise TypeError\n",
    "            \n",
    "        self.dir = directory\n",
    "        self.child_dir = child_dir\n",
    "        self.stack_dir = self.dir + self.child_dir\n",
    "        \n",
    "        shape = []\n",
    "        for name in sorted(os.listdir(self.dir)):\n",
    "            if not base.Q_img(name):\n",
    "                continue\n",
    "            shape.append(cv.imread(self.dir+'/'+name,cv.IMREAD_GRAYSCALE).shape)\n",
    "        \n",
    "        if len(set(shape)) == len(shape):\n",
    "            self._2d = True\n",
    "            self.dim = 2\n",
    "        else:\n",
    "            self._2d = False\n",
    "            self.dim = 3\n",
    "        \n",
    "    def binarize(self, options_dict=None):\n",
    "        \"\"\"Binarizes stack of experimental images using a set of image processing parameters in options_dict.\n",
    "        Note this enforces that all images have the same shape as the first image encountered by the for loop.\n",
    "        (i.e. the first alphanumeric titled image file)\n",
    "        \"\"\"\n",
    "        \n",
    "        if options_dict is None:\n",
    "            options = self.dir + '/img_options.json'\n",
    "            with open(options) as f:\n",
    "                options_dict = json.load(f)\n",
    "\n",
    "        if not os.path.isdir(self.dir + self.child_dir):\n",
    "            os.mkdir(self.dir + self.child_dir)\n",
    "\n",
    "        i=0\n",
    "        for name in sorted(os.listdir(self.dir)):\n",
    "            if not base.Q_img(name):\n",
    "                continue\n",
    "            else:\n",
    "                img_exp = cv.imread(self.dir+'/'+name,cv.IMREAD_GRAYSCALE)\n",
    "                if i == 0: shape = img_exp.shape\n",
    "                elif img_exp.shape != shape: continue\n",
    "                _, img_bin, _ = process_image.binarize(img_exp, options_dict)\n",
    "                plt.imsave(self.dir+self.child_dir+'/slice'+str(i)+'.tiff', img_bin, cmap=cm.gray)\n",
    "                i+=1\n",
    "        \n",
    "    def stack_to_gsd(self, name='skel.gsd', crop=None, skeleton=True, rotate=None, debubble=False):\n",
    "        \"\"\"Writes a .gsd file from the object's directory.\n",
    "        The name of the written .gsd is set as an attribute so it may be easily matched with its Graph object \n",
    "        Running this also sets the positions, shape attributes\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        start = time.time()\n",
    "        self.gsd_name = self.dir + '/' + name\n",
    "        img_bin=[]\n",
    "        \n",
    "        #Initilise i such that it starts at the lowest number belonging to the images in the stack_dir\n",
    "        #First require boolean mask to filter out non image files\n",
    "        olist = np.asarray(sorted(os.listdir(self.stack_dir)))\n",
    "        mask = list(base.Q_img(olist[i]) for i in range(len(olist)))\n",
    "        if len(mask) == 0:\n",
    "            raise error.ImageDirectoryError(self.stack_dir)\n",
    "        fname = sorted(olist[mask])[0] #First name\n",
    "        i = int(os.path.splitext(fname)[0][5:]) #Strip file type and 'slice' then convert to int\n",
    "        \n",
    "        #Generate 3d (or 2d) array from stack\n",
    "        for fname in sorted(os.listdir(self.stack_dir)):\n",
    "            if base.Q_img(fname):\n",
    "                img_slice = cv.imread(self.stack_dir+'/slice'+str(i)+'.tiff',cv.IMREAD_GRAYSCALE)\n",
    "                if rotate:\n",
    "                    image_center = tuple(np.array(img_slice.shape[1::-1]) / 2)\n",
    "                    rot_mat = cv.getRotationMatrix2D(image_center, rotate, 1.0)\n",
    "                    img_slice = cv.warpAffine(img_slice, rot_mat, img_slice.shape[1::-1], flags=cv.INTER_LINEAR)\n",
    "                img_bin.append(img_slice)\n",
    "                i=i+1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        img_bin = np.asarray(img_bin)\n",
    "        #Roll axes such that img_bin.shape[2]==1 when the graph is 2D\n",
    "        img_bin = np.swapaxes(img_bin, 0, 2)\n",
    "\n",
    "        #Note that numpy array slicing operations are carried out in reverse order!\n",
    "        #(...hence crop 2 and 3 before 0 and 1)\n",
    "        if crop and self._2d:\n",
    "            img_bin = img_bin[crop[2]:crop[3], crop[0]:crop[1]]\n",
    "        elif crop:\n",
    "            #TODO figure tf this bit out\n",
    "            img_bin = img_bin[crop[0]:crop[1], crop[2]:crop[3], crop[4]:crop[5]]\n",
    "        \n",
    "        if skeleton:\n",
    "            img_bin = skeletonize_3d(np.asarray(img_bin))\n",
    "        else:\n",
    "            img_bin = np.asarray(img_bin)\n",
    "        \n",
    "        self.img_bin_3d = img_bin            #Always 3d, even for 2d images\n",
    "        self.img_bin = np.squeeze(img_bin)   #3d for 3d images, 2d otherwise\n",
    "        \n",
    "        positions = np.asarray(np.where(np.asarray(img_bin) != 0)).T\n",
    "        self.shape = np.asarray(list(max(positions.T[i])+1 for i in (0,1,2)[0:self.dim]))\n",
    "        self.positions = positions\n",
    "        \n",
    "        with gsd.hoomd.open(name=self.gsd_name, mode='wb') as f:\n",
    "            s = gsd.hoomd.Snapshot()\n",
    "            s.particles.N = len(positions)\n",
    "            s.particles.position = base.shift(positions)\n",
    "            s.particles.types = ['A']\n",
    "            s.particles.typeid = ['0']*s.particles.N\n",
    "            f.append(s)\n",
    "        \n",
    "        end = time.time()\n",
    "        print('Ran stack_to_gsd() in ', end-start, 'for gsd with ', len(positions), 'particles')\n",
    "        \n",
    "        if debubble:\n",
    "            base.debubble(self)\n",
    "            self.gsd_name = self.dir + '/debubbled_' + name\n",
    "            \n",
    "            \n",
    "    def G_u(self):\n",
    "        \"\"\"Sets unweighted igraph object as an attribute\n",
    "        \"\"\"\n",
    "        G =  base.gsd_to_G(self.gsd_name, _2d = self._2d)\n",
    "        self.Gr = G\n",
    "        \n",
    "    def weighted_Laplacian(self):\n",
    "\n",
    "        L=np.asarray(self.Gr.laplacian(weights='weight'))\n",
    "        self.L = L\n",
    "\n",
    "class ResistiveNetwork(Graph):\n",
    "    \"\"\"Child of generic SGT Graph class.\n",
    "    Equipped with methods for analysing resistive flow networks\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        super().__init__(directory)\n",
    "        \n",
    "    def potential_distribution(self, plane, boundary1, boundary2, R_j=0, rho_dim=1, F_dim=1):\n",
    "        \"\"\"Solves for the potential distribution in a weighted network.\n",
    "        Source and sink nodes are connected according to a penetration boundary condition.\n",
    "        Sets the corresponding weighted Laplacian, potential and flow attributes.\n",
    "        The 'plane' arguement defines the axis along which the boundary arguements refer to.\n",
    "        R_j='infinity' enables the unusual case of all edges having the same unit resistance.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.G_u()\n",
    "        print('pre sub has ', self.Gr.vcount(), ' nodes')\n",
    "        self.Gr = base.sub_G(self.Gr)\n",
    "        print('post sub has ', self.Gr.vcount(), ' nodes')\n",
    "        if R_j != 'infinity':\n",
    "            print(self.Gr.vcount())\n",
    "            self.Gr = base.add_weights(self, weight_type='Resistance', R_j=R_j, rho_dim=rho_dim)\n",
    "            print(self.Gr.vcount())\n",
    "            weight_array = np.asarray(self.Gr.es['weight']).astype(float)\n",
    "            weight_array = weight_array[~np.isnan(weight_array)]\n",
    "            weight_avg =np.mean(weight_array)\n",
    "        else:\n",
    "            self.Gr.es['weight'] = np.ones(self.Gr.ecount())\n",
    "            weight_avg = 1\n",
    "\n",
    "        #Add source and sink nodes:\n",
    "        source_id = max(self.Gr.vs).index + 1\n",
    "        sink_id = source_id + 1\n",
    "        self.Gr.add_vertices(2)\n",
    "\n",
    "        print('Graph has max ', self.shape)\n",
    "        axes = np.array([0,1,2])[0:self.dim]\n",
    "        indices = axes[axes!=plane]\n",
    "        plane_centre1 = np.zeros(self.dim, dtype=int)\n",
    "        delta = np.zeros(self.dim, dtype=int)\n",
    "        delta[plane] = 10 #Arbitrary. Standardize?\n",
    "        for i in indices: plane_centre1[i] = self.shape[i]/2\n",
    "        plane_centre2 = np.copy(plane_centre1)\n",
    "        plane_centre2[plane] = self.shape[plane]\n",
    "        source_coord = plane_centre1 - delta \n",
    "        sink_coord = plane_centre2 + delta\n",
    "        print('source coord is ', source_coord)\n",
    "        print('sink coord is ', sink_coord)\n",
    "        self.Gr.vs[source_id]['o'] = source_coord\n",
    "        self.Gr.vs[sink_id]['o'] = sink_coord\n",
    "\n",
    "    #Connect nodes on a given boundary to the external current nodes\n",
    "        print('Before connecting external nodes, G has vcount ', self.Gr.vcount())\n",
    "        for node in self.Gr.vs:\n",
    "            if node['o'][plane] > boundary1[0] and node['o'][plane] < boundary1[1]:\n",
    "                self.Gr.add_edges([(node.index, source_id)])\n",
    "                self.Gr.es[self.Gr.get_eid(node.index,source_id)]['weight'] = weight_avg\n",
    "                self.Gr.es[self.Gr.get_eid(node.index,source_id)]['pts'] = base.connector(source_coord,node['o'])\n",
    "            if node['o'][plane] > boundary2[0] and node['o'][plane] < boundary2[1]:\n",
    "                self.Gr.add_edges([(node.index, sink_id)])\n",
    "                self.Gr.es[self.Gr.get_eid(node.index,sink_id)]['weight'] = weight_avg \n",
    "                self.Gr.es[self.Gr.get_eid(node.index,sink_id)]['pts'] = base.connector(sink_coord,node['o'])\n",
    "\n",
    "    #Write skeleton connected to external node\n",
    "        print(self.Gr.is_connected(), ' connected')\n",
    "        print('After connecting external nodes, G has vcount ', self.Gr.vcount())\n",
    "        connected_name = os.path.split(self.gsd_name)[0] + '/connected_' + os.path.split(self.gsd_name)[1] \n",
    "        #connected_name = self.stack_dir + '/connected_' + self.gsd_name \n",
    "        base.G_to_gsd(self.Gr, connected_name)\n",
    "\n",
    "        self.weighted_Laplacian()\n",
    "        F = np.zeros(sink_id+1)\n",
    "        print(F.shape,'F')\n",
    "        print(self.L.shape, 'L')\n",
    "        F[source_id] = F_dim\n",
    "        F[sink_id] = -F_dim\n",
    "        np.save(self.stack_dir+'/L.npy',self.L)\n",
    "        np.save(self.stack_dir+'/F.npy',F)\n",
    "        P = np.matmul(np.linalg.pinv(self.L, hermitian=True),F)\n",
    "        np.save(self.stack_dir+'/P.npy',P)\n",
    "\n",
    "        self.P = P\n",
    "        self.F = F\n",
    "\n",
    "class StructuralNetwork(Graph):\n",
    "    \"\"\"Child of generic SGT Graph class.\n",
    "    Equipped with methods for analysing structural networks\n",
    "    \"\"\"\n",
    "    def __init__(self, directory):\n",
    "        super().__init__(directory)\n",
    "        \n",
    "    def G_calc(self):\n",
    "        avg_indices = dict()\n",
    "\n",
    "        operations = [self.Gr.diameter, self.Gr.density, self.Gr.transitivity_undirected, self.Gr.assortativity_degree]\n",
    "        names = ['Diameter', 'Density', 'Clustering', 'Assortativity by degree']\n",
    "\n",
    "        for operation,name in zip(operations,names):\n",
    "            start = time.time()\n",
    "            avg_indices[name] = operation()\n",
    "            end = time.time()\n",
    "            print('Calculated ', name, ' in ', end-start)\n",
    "            \n",
    "        self.G_attributes = avg_indices\n",
    "        \n",
    "    def node_calc(self):\n",
    "        self.Betweenness = self.Gr.betweenness()\n",
    "        self.Closeness = self.Gr.closeness()\n",
    "        self.Degree = self.Gr.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medical-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran stack_to_gsd() in  26.416732788085938 for gsd with  43095 particles\n",
      "gsd_to_G canvas has shape  (100, 100, 100)\n",
      "[[ 0  1 10]]\n",
      "(0, 227, array([[ 0,  1, 10],\n",
      "       [ 1,  1, 10],\n",
      "       [ 2,  1, 10],\n",
      "       [ 3,  1, 10],\n",
      "       [ 4,  1, 10],\n",
      "       [ 5,  1, 10],\n",
      "       [ 6,  1, 10],\n",
      "       [ 7,  1, 10],\n",
      "       [ 8,  2,  9],\n",
      "       [ 9,  3,  9],\n",
      "       [10,  4,  9]], dtype=int16))\n",
      "Ran gsd_to_G in  3.744230031967163 for a graph with  2015 nodes.\n",
      "gsd_to_G canvas has shape  (100, 100, 100)\n",
      "[[ 0  1 10]]\n",
      "(0, 227, array([[ 0,  1, 10],\n",
      "       [ 1,  1, 10],\n",
      "       [ 2,  1, 10],\n",
      "       [ 3,  1, 10],\n",
      "       [ 4,  1, 10],\n",
      "       [ 5,  1, 10],\n",
      "       [ 6,  1, 10],\n",
      "       [ 7,  1, 10],\n",
      "       [ 8,  2,  9],\n",
      "       [ 9,  3,  9],\n",
      "       [10,  4,  9]], dtype=int16))\n",
      "Ran gsd_to_G in  3.6526620388031006 for a graph with  2015 nodes.\n",
      "pre sub has  2015  nodes\n",
      "pre sub has  2015  nodes\n",
      "post sub has  1600  nodes\n",
      "post sub has  1600  nodes\n",
      "1600\n",
      "graph_shape is  [99, 99]  and img_shape is  (1024, 1536)\n",
      "Loaded img in  1.1920928955078125e-06\n",
      "img_bin has shape  (100, 100, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alaink/Software/StructuralGTEdits/StructuralGT/GetWeights_3d.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return vec/np.linalg.norm(vec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added weights to a graph  with  1600 nodes in  0.3894069194793701\n",
      "1600\n",
      "Graph has max  [100 100 100]\n",
      "source coord is  [-10  50  50]\n",
      "sink coord is  [110  50  50]\n",
      "Before connecting external nodes, G has vcount  1602\n",
      "True  connected\n",
      "After connecting external nodes, G has vcount  1602\n",
      "(1602,) F\n",
      "(1602, 1602) L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "implicit data copy when writing chunk: log/particles/P\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran stack_to_gsd() in  28.616368055343628 for gsd with  138415 particles\n",
      "gsd_to_G canvas has shape  (200, 200, 200)\n",
      "[[ 0  0 21]\n",
      " [ 0  1 21]]\n",
      "(1, 774, array([[0, 1, 8],\n",
      "       [1, 2, 8],\n",
      "       [2, 2, 8],\n",
      "       [3, 2, 8],\n",
      "       [4, 3, 8],\n",
      "       [5, 3, 7],\n",
      "       [6, 3, 7],\n",
      "       [7, 3, 7],\n",
      "       [8, 4, 7]], dtype=int16))\n",
      "Ran gsd_to_G in  16.71473002433777 for a graph with  13217 nodes.\n",
      "gsd_to_G canvas has shape  (200, 200, 200)\n",
      "[[ 0  0 21]\n",
      " [ 0  1 21]]\n",
      "(1, 774, array([[0, 1, 8],\n",
      "       [1, 2, 8],\n",
      "       [2, 2, 8],\n",
      "       [3, 2, 8],\n",
      "       [4, 3, 8],\n",
      "       [5, 3, 7],\n",
      "       [6, 3, 7],\n",
      "       [7, 3, 7],\n",
      "       [8, 4, 7]], dtype=int16))\n",
      "Ran gsd_to_G in  16.649702310562134 for a graph with  13217 nodes.\n",
      "pre sub has  13217  nodes\n",
      "pre sub has  13217  nodes\n",
      "post sub has  10028  nodes\n",
      "post sub has  10028  nodes\n",
      "10028\n",
      "graph_shape is  [199, 199]  and img_shape is  (1024, 1536)\n",
      "Loaded img in  0.0\n",
      "img_bin has shape  (200, 200, 200)\n",
      "Added weights to a graph  with  10028 nodes in  1.957448959350586\n",
      "10028\n",
      "Graph has max  [200 200 200]\n",
      "source coord is  [-10 100 100]\n",
      "sink coord is  [210 100 100]\n",
      "Before connecting external nodes, G has vcount  10030\n",
      "True  connected\n",
      "After connecting external nodes, G has vcount  10030\n",
      "(10030,) F\n",
      "(10030, 10030) L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "implicit data copy when writing chunk: log/particles/P\n"
     ]
    }
   ],
   "source": [
    "g = ResistiveNetwork('TestData/pores-hi-res-crop')\n",
    "g.stack_to_gsd(crop=[0,100,0,100,0,100])\n",
    "g.G_u()\n",
    "g.potential_distribution(0, [0,20], [80,100])\n",
    "base.Node_labelling(g, g.P, 'P', 'test1.gsd')\n",
    "\n",
    "\n",
    "h = ResistiveNetwork('TestData/pores-hi-res-crop')\n",
    "h.stack_to_gsd(crop=[100,300,100,300,100,300])\n",
    "h.G_u()\n",
    "h.potential_distribution(0, [0,20], [180,200])\n",
    "base.Node_labelling(h, h.P, 'P', 'test2.gsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "palestinian-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran stack_to_gsd() in  21.676934242248535 for gsd with  43395 particles\n",
      "gsd_to_G canvas has shape  (100, 100, 100)\n",
      "[[0 0 4]]\n",
      "(0, 137, array([[0, 0, 4],\n",
      "       [1, 0, 4],\n",
      "       [2, 0, 4],\n",
      "       [3, 0, 4],\n",
      "       [4, 1, 4],\n",
      "       [5, 1, 4],\n",
      "       [6, 1, 4],\n",
      "       [7, 1, 4],\n",
      "       [8, 1, 4],\n",
      "       [9, 0, 5]], dtype=int16))\n",
      "Ran gsd_to_G in  3.7469260692596436 for a graph with  2083 nodes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StructuralNetwork' object has no attribute 'potential_distribution'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-db48ebf96f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_to_gsd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotential_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_to_gsd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'skel2.gsd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StructuralNetwork' object has no attribute 'potential_distribution'"
     ]
    }
   ],
   "source": [
    "g = StructuralNetwork('TestData/fibres-hi-res-crop')\n",
    "g.stack_to_gsd(crop=[0,100,0,100,0,100])\n",
    "g.G_u()\n",
    "g.potential_distribution(0, [0,20], [80,100])\n",
    "\n",
    "g.stack_to_gsd(crop=[100,300,100,300,100,300], name = 'skel2.gsd')\n",
    "g.G_u()\n",
    "g.potential_distribution(0, [0,20], [80,100])\n",
    "base.Node_labelling(g, g.Degree, 'Degree', 'test2.gsd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotation test\n",
    "#Continuous rotation analysis\n",
    "#Testing base.py implementation\n",
    "#This implementation rotates the image itself\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "g = ResistiveNetwork('TestData/AgNWN_10um')\n",
    "g.binarize()\n",
    "\n",
    "#thetas = np.linspace(0.01,350, 36)\n",
    "thetas = (0,30,60,90,180)\n",
    "\n",
    "#crop = 359\n",
    "\n",
    "#Need to reassign weights from a temporary rotated binary image\n",
    "#First write the temporary image\n",
    "#Must calculate positions for the crop because this crop is origin cornered (and not origin centred, like the one above)\n",
    "img_bin = cv.imread(g.stack_dir+'/slice0.tiff') #Original image\n",
    "image_center = tuple(np.array(img_bin.shape[1::-1]) / 2)\n",
    "short_length = img_bin.shape[img_bin.shape == max(img_bin.shape)]\n",
    "long_length = max(img_bin.shape)\n",
    "ISS = (short_length**2/2)**0.5\n",
    "L1 = int((long_length - ISS)/2)\n",
    "L3 = int(ISS+L1)\n",
    "L2 = int((short_length - ISS)/2)\n",
    "L4 = int(ISS+L2)\n",
    "o_corn_crop = [L2,L1,L4,L3]\n",
    "dims = L2-L1\n",
    "\n",
    "\n",
    "R_j = 0\n",
    "O_eff_df = []\n",
    "Ax_df = []\n",
    "Ay_df = []\n",
    "theta_df = []\n",
    "for theta in thetas:\n",
    "    g.stack_to_gsd(name='/Rotations/rot_skel.gsd', crop=[L1,L3,L2,L4], rotate=theta)\n",
    "    with Image.open(g.stack_dir+'/slice0.tiff') as im:\n",
    "        img_crop = im.crop(box=[L2,L1,L4,L3])\n",
    "        img_rot=im.rotate(theta*180/np.pi) #Rotate\n",
    "        img_rot.save(g.dir+'/Rotations/slice0.tiff') \n",
    "\n",
    "    g.potential_distribution(0, [0,20], [727-20,727], R_j=0, rho_dim=1, F_dim=1)\n",
    "    base.Node_labelling(g, g.P, 'P', 'test.gsd')\n",
    "    #Ax, Ay = base.gyration_moments(G, sampling = 0.05)\n",
    "    #L = g.L\n",
    "    #Q = np.linalg.pinv(L)\n",
    "    #O_eff = Q[-1,-1]+Q[-2,-2]-2*Q[-1,-2]\n",
    "    \n",
    "    #stop\n",
    "    \n",
    "    #O_eff_df.append(O_eff)\n",
    "    #Ax_df.append(Ax)\n",
    "    #Ay_df.append(Ay)\n",
    "    #theta_df.append(theta)\n",
    "\n",
    "#df_cont = pd.DataFrame(columns=['Theta','O_eff','Ax','Ay'])\n",
    "#df_cont['O_eff'] = O_eff_df\n",
    "#df_cont['Ax'] = Ax_df\n",
    "#df_cont['Ay'] = Ay_df\n",
    "#df_cont['Theta'] = theta_df\n",
    "#df_cont.to_csv('AgNWN.csv')\n",
    "\n",
    "#df_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bin.shape\n",
    "L2-L4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_slice = cv.imread(g.stack_dir+'/slice'+str(0)+'.tiff',cv.IMREAD_GRAYSCALE)\n",
    "img_bin=[]\n",
    "img_bin.append(img_slice)\n",
    "img_bin = np.asarray(img_bin)\n",
    "img_bin = np.swapaxes(img_bin, 0, 2)\n",
    "print(img_bin.shape)\n",
    "img_bin = img_bin[crop[2]:crop[3],crop[0]:crop[1]]\n",
    "print(img_bin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(_class,method):\n",
    "    \"\"\"Print the runtime of the decorated function\"\"\"\n",
    "    @functools.wraps(method)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start_time = time.perf_counter()    # 1\n",
    "        value = _method(*args, **kwargs)\n",
    "        end_time = time.perf_counter()      # 2\n",
    "        run_time = end_time - start_time    # 3\n",
    "        print(f\"Finished {method.__name__!r} in {run_time:.4f} secs\")\n",
    "        print(_class)\n",
    "        print(method)\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
